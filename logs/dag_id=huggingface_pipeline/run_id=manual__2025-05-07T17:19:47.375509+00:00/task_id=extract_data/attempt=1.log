[2025-05-07T17:19:48.042+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:19:47.375509+00:00 [queued]>
[2025-05-07T17:19:48.099+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:19:47.375509+00:00 [queued]>
[2025-05-07T17:19:48.101+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-05-07T17:19:48.103+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2025-05-07T17:19:48.104+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-05-07T17:19:48.113+0000] {taskinstance.py:1304} INFO - Executing <Task(PythonOperator): extract_data> on 2025-05-07 17:19:47.375509+00:00
[2025-05-07T17:19:48.120+0000] {standard_task_runner.py:55} INFO - Started process 306 to run task
[2025-05-07T17:19:48.124+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'huggingface_pipeline', 'extract_data', 'manual__2025-05-07T17:19:47.375509+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/huggingface_pipeline.py', '--cfg-path', '/tmp/tmph8zqh4ob']
[2025-05-07T17:19:48.128+0000] {standard_task_runner.py:83} INFO - Job 22: Subtask extract_data
[2025-05-07T17:19:48.150+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:249 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T17:19:48.206+0000] {task_command.py:389} INFO - Running <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:19:47.375509+00:00 [running]> on host 2ee681e0adcd
[2025-05-07T17:19:48.267+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=huggingface_pipeline
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2025-05-07T17:19:47.375509+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-05-07T17:19:47.375509+00:00
[2025-05-07T17:19:49.845+0000] {logging_mixin.py:137} INFO - Downloading and preparing dataset None/plain_text to /home/***/.cache/huggingface/datasets/parquet/plain_text-cafccae0f4e408dc/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...
[2025-05-07T17:19:50.113+0000] {logging_mixin.py:137} WARNING - Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]
[2025-05-07T17:19:50.117+0000] {logging_mixin.py:137} WARNING - Downloading data files: 100%|##########| 2/2 [00:00<00:00, 2542.77it/s]
[2025-05-07T17:19:50.120+0000] {logging_mixin.py:137} WARNING - Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]
[2025-05-07T17:19:50.124+0000] {logging_mixin.py:137} WARNING - Extracting data files: 100%|##########| 2/2 [00:00<00:00, 1151.17it/s]
[2025-05-07T17:19:50.126+0000] {logging_mixin.py:137} WARNING - Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]
[2025-05-07T17:19:50.304+0000] {logging_mixin.py:137} WARNING - Generating train split:  80%|########  | 20000/25000 [00:00<00:00, 113964.50 examples/s]
[2025-05-07T17:19:50.341+0000] {logging_mixin.py:137} WARNING -                                                                                         
[2025-05-07T17:19:50.343+0000] {logging_mixin.py:137} WARNING - 
[2025-05-07T17:19:50.344+0000] {logging_mixin.py:137} WARNING - Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]
[2025-05-07T17:19:50.467+0000] {logging_mixin.py:137} WARNING - Generating test split:  80%|########  | 20000/25000 [00:00<00:00, 165239.70 examples/s]
[2025-05-07T17:19:50.489+0000] {logging_mixin.py:137} WARNING -                                                                                        
[2025-05-07T17:19:50.508+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/huggingface_pipeline.py", line 14, in extract_data
    dataset = load_dataset("imdb", split="train[:100]")
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/load.py", line 1815, in load_dataset
    storage_options=storage_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/builder.py", line 913, in download_and_prepare
    **download_and_prepare_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/builder.py", line 1022, in _download_and_prepare
    verify_splits(self.info.splits, split_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/utils/info_utils.py", line 91, in verify_splits
    raise ExpectedMoreSplits(str(set(expected_splits) - set(recorded_splits)))
datasets.utils.info_utils.ExpectedMoreSplits: {'unsupervised'}
[2025-05-07T17:19:50.524+0000] {taskinstance.py:1327} INFO - Marking task as FAILED. dag_id=huggingface_pipeline, task_id=extract_data, execution_date=20250507T171947, start_date=20250507T171948, end_date=20250507T171950
[2025-05-07T17:19:50.534+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 22 for task extract_data ({'unsupervised'}; 306)
[2025-05-07T17:19:50.593+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-05-07T17:19:50.614+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
