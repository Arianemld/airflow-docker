[2025-05-07T17:17:33.721+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:17:32.585276+00:00 [queued]>
[2025-05-07T17:17:33.779+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:17:32.585276+00:00 [queued]>
[2025-05-07T17:17:33.781+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-05-07T17:17:33.782+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2025-05-07T17:17:33.784+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-05-07T17:17:33.792+0000] {taskinstance.py:1304} INFO - Executing <Task(PythonOperator): extract_data> on 2025-05-07 17:17:32.585276+00:00
[2025-05-07T17:17:33.798+0000] {standard_task_runner.py:55} INFO - Started process 222 to run task
[2025-05-07T17:17:33.802+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'huggingface_pipeline', 'extract_data', 'manual__2025-05-07T17:17:32.585276+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/huggingface_pipeline.py', '--cfg-path', '/tmp/tmpo9ut9qxx']
[2025-05-07T17:17:33.805+0000] {standard_task_runner.py:83} INFO - Job 21: Subtask extract_data
[2025-05-07T17:17:33.820+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:249 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T17:17:33.866+0000] {task_command.py:389} INFO - Running <TaskInstance: huggingface_pipeline.extract_data manual__2025-05-07T17:17:32.585276+00:00 [running]> on host 2ee681e0adcd
[2025-05-07T17:17:33.920+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=huggingface_pipeline
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2025-05-07T17:17:32.585276+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-05-07T17:17:32.585276+00:00
[2025-05-07T17:17:35.428+0000] {logging_mixin.py:137} INFO - Downloading and preparing dataset None/plain_text to /home/***/.cache/huggingface/datasets/parquet/plain_text-cafccae0f4e408dc/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...
[2025-05-07T17:17:35.624+0000] {logging_mixin.py:137} WARNING - Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]
[2025-05-07T17:17:35.627+0000] {logging_mixin.py:137} WARNING - Downloading data files: 100%|##########| 2/2 [00:00<00:00, 4228.13it/s]
[2025-05-07T17:17:35.630+0000] {logging_mixin.py:137} WARNING - Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]
[2025-05-07T17:17:35.633+0000] {logging_mixin.py:137} WARNING - Extracting data files: 100%|##########| 2/2 [00:00<00:00, 1692.62it/s]
[2025-05-07T17:17:35.635+0000] {logging_mixin.py:137} WARNING - Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]
[2025-05-07T17:17:35.762+0000] {logging_mixin.py:137} WARNING - Generating train split: 100%|##########| 25000/25000 [00:00<00:00, 200193.21 examples/s]
[2025-05-07T17:17:35.765+0000] {logging_mixin.py:137} WARNING -                                                                                         
[2025-05-07T17:17:35.767+0000] {logging_mixin.py:137} WARNING - 
[2025-05-07T17:17:35.769+0000] {logging_mixin.py:137} WARNING - Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]
[2025-05-07T17:17:35.876+0000] {logging_mixin.py:137} WARNING - Generating test split: 100%|##########| 25000/25000 [00:00<00:00, 239457.77 examples/s]
[2025-05-07T17:17:35.878+0000] {logging_mixin.py:137} WARNING -                                                                                        
[2025-05-07T17:17:35.902+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/huggingface_pipeline.py", line 14, in extract_data
    dataset = load_dataset("imdb")
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/load.py", line 1815, in load_dataset
    storage_options=storage_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/builder.py", line 913, in download_and_prepare
    **download_and_prepare_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/builder.py", line 1022, in _download_and_prepare
    verify_splits(self.info.splits, split_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/datasets/utils/info_utils.py", line 91, in verify_splits
    raise ExpectedMoreSplits(str(set(expected_splits) - set(recorded_splits)))
datasets.utils.info_utils.ExpectedMoreSplits: {'unsupervised'}
[2025-05-07T17:17:35.918+0000] {taskinstance.py:1327} INFO - Marking task as FAILED. dag_id=huggingface_pipeline, task_id=extract_data, execution_date=20250507T171732, start_date=20250507T171733, end_date=20250507T171735
[2025-05-07T17:17:35.958+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 21 for task extract_data ({'unsupervised'}; 222)
[2025-05-07T17:17:36.019+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-05-07T17:17:36.040+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
